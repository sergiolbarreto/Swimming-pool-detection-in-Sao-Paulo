# ğŸŠâ€â™‚ï¸ Swimming Pool Detection in SÃ£o Paulo

Este projeto tem como objetivo **estimar o nÃºmero de piscinas na cidade de SÃ£o Paulo** a partir de **imagens de satÃ©lite** e **modelos de detecÃ§Ã£o de objetos** (YOLO).  
Foi desenvolvido como parte de um desafio de Machine Learning que combina **visÃ£o computacional e inferÃªncia estatÃ­stica**.

---

## ğŸ¯ Desafio

> **How Many Pools in SÃ£o Paulo?**  
> **Goal:** Estimate the number of swimming pools in SÃ£o Paulo using ML + satellite images.  
>  
> **Tasks**
> - Sample rooftops from Google Maps or INPE  
> - Train a detector (> 0.65 mAP) for pools  
> - Use statistics to extrapolate total count  
>
> **Bonus**
> - Folium map with pool density  
> - District-wise comparison

---

## ğŸ§­ Etapas do Projeto

### 1. Tentativa inicial com dados pÃºblicos (GeoSampa)
A primeira ideia foi **buscar um dataset pronto** de imagens de satÃ©lite de SÃ£o Paulo, especialmente no **GeoSampa**.  
Apesar de o portal disponibilizar ortofotos corrigidas, o processo de **extraÃ§Ã£o e recorte em blocos uniformes** mostrou-se inviÃ¡vel no tempo disponÃ­vel.  
Cada imagem precisava ser manualmente localizada e baixada, inviabilizando a automaÃ§Ã£o.

---

### 2. ExtraÃ§Ã£o de imagens via Google Maps API
A soluÃ§Ã£o adotada foi usar a **Google Maps Static API**, atravÃ©s da **Google Cloud Platform**, para **baixar imagens de satÃ©lite diretamente de coordenadas de SÃ£o Paulo**.

O script `download_sp_images.py`:
- gera coordenadas **aleatÃ³rias estratificadas por renda** (`high_income`, `middle_income`, `low_income`);
- usa a API do Google Maps para baixar blocos 640Ã—640 px (zoom 19);
- impÃµe uma **distÃ¢ncia mÃ­nima de 150 m** entre pontos para evitar sobreposiÃ§Ã£o;
- registra metadados como `lat`, `lon`, `stratum` e `filepath` no arquivo  
  `dataset/download_metadata.csv`.

Ãreas-alvo: Jardins, Morumbi, Brooklin, Pinheiros (alta renda); Mooca, Pompeia (mÃ©dia); Itaquera e CapÃ£o Redondo (baixa).  
Foram obtidas cerca de **600 imagens iniciais**.

---

### 3. Rotulagem manual das piscinas
Como nÃ£o havia dataset rotulado de SÃ£o Paulo, realizei o rotulamento manual  de uma parte das imagens usando o **LabelMe**.  
Cada piscina foi marcada com polÃ­gonos.  
Os arquivos `.json` foram convertidos para o formato YOLO com:

```bash
python3 prepare_dataset.py
```

Resultado:
```
dataset/yolo_sp/images   â†’ imagens
dataset/yolo_sp/labels   â†’ labels YOLO
```

---

### 4. Uso do dataset de Belo Horizonte (BH)
Devido Ã  limitaÃ§Ã£o de tempo para rotular grandes volumes, utilizei o **dataset de Belo Horizonte**, que possui imagens urbanas semelhantes Ã s de SÃ£o Paulo.  
A textura urbana e a disposiÃ§Ã£o das construÃ§Ãµes sÃ£o comparÃ¡veis, o que permite **transfer learning consistente**.

---

### 5. Modelo e treinamento
O modelo escolhido foi o **YOLOv8**, que oferece:
- arquitetura leve e rÃ¡pida;  
- **data augmentation automÃ¡tica** (rotaÃ§Ã£o, flips, brilho etc.);  
- suporte nativo ao formato YOLO.

Treinamento no dataset BH:
```
epochs = 50
batch  = 16
imgsz  = 640
optimizer = SGD
```

**MÃ©tricas finais do treinamento:**

| MÃ©trica | Valor |
|----------|--------|
| Precision | **0.8877** |
| Recall | **0.8449** |
| mAP50 | **0.9159** |
| mAP50-95 | **0.6203** |
| box_loss | 0.9867 |
| cls_loss | 0.5290 |
| dfl_loss | 0.8055 |

ğŸ“ˆ O modelo atingiu **excelente desempenho (mAP50 > 0.9)**, superando o objetivo > 0.65 mAP do desafio, com alta precisÃ£o e recall.

---

### 6. ValidaÃ§Ã£o e teste em SÃ£o Paulo
Com o modelo treinado em BH, realizei a validaÃ§Ã£o nas imagens de SÃ£o Paulo.  
Inicialmente usei todas as imagens, mas muitas **nÃ£o continham piscinas**.  
Para avaliar o desempenho real, filtrei o conjunto apenas para **imagens com piscinas**.
Os resultados mostram **boa generalizaÃ§Ã£o**, mas tambÃ©m a diferenÃ§a de domÃ­nio entre BH e SP.

---

### 7. DetecÃ§Ã£o nas imagens de SÃ£o Paulo

Usando o modelo YOLOv8 treinado em BH, rodei a detecÃ§Ã£o em todas as imagens extraÃ­das de SÃ£o Paulo.  
ParÃ¢metros principais:

```
conf = 0.45
iou  = 0.70
imgsz = 640
```

**Resultados da detecÃ§Ã£o:**
```
âœ… DetecÃ§Ã£o concluÃ­da!
ğŸ“Š Total de detecÃ§Ãµes: 929
ğŸ“ CSV salvo em: results/pools_sp_detection_full/detections_sp_full.csv
ğŸ“‚ Resultados visuais: results/pools_sp_detection_full/detect_sp_full

ğŸŠ Piscinas detectadas: 929
ğŸ“ˆ MÃ©dia: 0.67 piscinas por imagem
```

As detecÃ§Ãµes foram cruzadas com o `download_metadata.csv`, associando cada piscina Ã  sua localizaÃ§Ã£o (lat/lon) e ao estrato socioeconÃ´mico.

---

### 8. Estimativa populacional de piscinas

A estimativa do nÃºmero total de piscinas em SÃ£o Paulo foi feita via **extrapolaÃ§Ã£o estatÃ­stica estratificada**:

#### 1ï¸âƒ£ CÃ¡lculo da densidade por estrato

| Estrato | Densidade observada (piscinas/kmÂ²) |
|----------|------------------------------------|
| Alta renda | **14.83** |
| MÃ©dia renda | **4.00** |
| Baixa renda | **3.53** |

Cada tile corresponde a â‰ˆ 0.0583 kmÂ², o que permite estimar a densidade amostral.

#### 2ï¸âƒ£ Estimativa bruta
Multiplicando a densidade mÃ©dia ponderada pela Ã¡rea total da cidade (â‰ˆ 1 521 kmÂ²):

```
ğŸŒ† ESTIMATIVA BRUTA: 16 306 piscinas
```

#### 3ï¸âƒ£ CorreÃ§Ã£o por recall (real = 0.15)

O modelo detecta cerca de 15 % das piscinas visÃ­veis.  
Aplicou-se o fator 1/recall para compensar a subdetecÃ§Ã£o:

\[
\text{Estimativa ajustada} = \frac{16 306}{0.15} \approx 108 712
\]

### 9. Metodologia estatÃ­stica

A extrapolaÃ§Ã£o foi feita por **amostragem estratificada**, inspirada em tÃ©cnicas de sensoriamento remoto:

1. **EstratificaÃ§Ã£o** por renda (baixa, mÃ©dia, alta).  
2. **CÃ¡lculo de densidade** de piscinas por kmÂ² em cada estrato.  
3. **PonderaÃ§Ã£o espacial** pela Ã¡rea ocupada de cada estrato na cidade.  
4. **CorreÃ§Ã£o por recall**, compensando subdetecÃ§Ã£o.  
5. **Soma ponderada** â†’ estimativa global final.

Essa abordagem considera:
- desempenho real do modelo;  
- desigualdade espacial da distribuiÃ§Ã£o de piscinas;  
- tamanho e Ã¡rea amostrada.

ğŸ“ˆ **Resultado final:**  
> **â‰ˆ 108 mil piscinas na cidade de SÃ£o Paulo**  
---
Gerei um folium map como foi pedido, estÃ¡ no arquivo html `pool_density_map.html`.
Ele foi gerado pelo script `generate_pool_heatmap.py`
<img width="1288" height="686" alt="image" src="https://github.com/user-attachments/assets/9043bded-5a89-4f4f-abdc-0e1763568fc5" />


## ğŸ§© OrganizaÃ§Ã£o do pipeline

```
dataset/
â”œâ”€â”€ raw_images/              # imagens baixadas pela API
â”œâ”€â”€ annotations/             # arquivos .json do LabelMe
â”œâ”€â”€ yolo_sp/                 # dataset convertido para YOLO
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ download_metadata.csv    # metadados (lat, lon, stratum, path)

results/
â”œâ”€â”€ pools_bh_train/          # modelo YOLO treinado em BH
â”œâ”€â”€ pools_sp_validation/     # mÃ©tricas de validaÃ§Ã£o em SP
â””â”€â”€ pools_sp_detection_full/ # detecÃ§Ãµes + estimativas finais
```

---

## ğŸš€ ExecuÃ§Ã£o passo a passo

1. **Instalar dependÃªncias**
   ```bash
   pip install -r requirements.txt
   ```

2. **Baixar imagens**
   ```bash
   python3 download_sp_images.py
   ```

3. **Rotular manualmente**
   ```bash
   labelme dataset/raw_images
   ```

4. **Converter rÃ³tulos para YOLO**
   ```bash
   python3 prepare_dataset.py
   ```

5. **Treinar o modelo (opcional)**
   ```bash
   python3 train_bh.py
   ```

6. **Rodar detecÃ§Ã£o**
   ```bash
   python3 detect_sp.py
   ```

7. **Gerar estimativa**
   ```bash
   python3 estimate_sp_pools.py
   ```

---

## ğŸ”® PrÃ³ximos passos

- **Ampliar o dataset** de SP, rotulando mais imagens via Google API.  
- **Fine-tuning local**, ajustando o modelo de BH para o domÃ­nio paulistano.  
- **Novas classes** (*caixa dâ€™Ã¡gua*, *piscina desativada*, *quadra*), reduzindo falsos positivos.  

---

## ğŸ§  ConclusÃ£o

Este projeto demonstrou um **pipeline completo de visÃ£o computacional e anÃ¡lise estatÃ­stica aplicada ao mapeamento urbano**, incluindo:
**extraÃ§Ã£o â†’ rotulagem â†’ treinamento â†’ validaÃ§Ã£o â†’ estimativa.**

---
